services:
  digitalisation_toolkit-nginx:
    container_name: digitalisation_toolkit-nginx
    image: nginx:1.27.2-alpine
    ports:
      - "8080:80"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
    networks:
      - digitalisation_toolkit-network
    restart: unless-stopped

  digitalisation_toolkit-frontend:
    container_name: digitalisation_toolkit-frontend
    restart: unless-stopped
    build:
      context: ./frontend
    env_file:
      - ./frontend/.env
    environment:
      # LLM API URLs (Replace with your actual API endpoints)
      - TRANSLATION_API_URL=${TRANSLATION_API_URL:-http://webworkdgx/vllm_sealion}
      - GENERAL_API_URL=${GENERAL_API_URL:-http://webworkdgx/vllm_qwen2_5}
      # API Tokens (Set these in your environment or .env file)
      - TRANSLATION_API_TOKEN=${TRANSLATION_API_TOKEN}
      - GENERAL_API_TOKEN=${GENERAL_API_TOKEN}
    networks:
      - digitalisation_toolkit-network
    depends_on:
      - digitalisation_toolkit-nginx

  digitalisation_toolkit-backend:
    container_name: digitalisation_toolkit-backend
    build:
      context: ./backend
    env_file:
      - ./backend/.env
    networks:
      - digitalisation_toolkit-network
    restart: unless-stopped
    depends_on:
      - digitalisation_toolkit-nginx
    runtime: nvidia
    environment:
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
      - CUDA_DEVICE_ORDER=PCI_BUS_ID
      - CUDA_VISIBLE_DEVICES=0,1,2,3
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

networks:
  digitalisation_toolkit-network:
    name: digitalisation_toolkit-network
    driver: bridge
